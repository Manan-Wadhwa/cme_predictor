{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853685af-f01d-4f23-b40c-92d7327971b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacepy import pycdf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from cdflib import CDF, cdfepoch\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72dbe40-d4d3-4263-a77d-8f578fd4caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renamed the files to be named from start date-time to end date-time\n",
    "for file in cdf_files:\n",
    "    try:\n",
    "        cdf = cdflib.CDF(file)\n",
    "\n",
    "        global_atts = cdf.globalattsget()\n",
    "\n",
    "        start_cdf = global_atts['Observation_start_time'][0]\n",
    "        end_cdf = global_atts['Observation_end_time'][0]\n",
    "\n",
    "        start_time = cdfepoch.to_datetime(start_cdf)\n",
    "        end_time = cdfepoch.to_datetime(end_cdf)\n",
    "\n",
    "        start_str = str(start_time[0])\n",
    "        end_str = str(end_time[0])\n",
    "\n",
    "        new_name = f\"{start_str}_{end_str}.cdf\"\n",
    "        \n",
    "        if os.path.exists(new_name):\n",
    "            print(f\"Warning: {new_name} already exists. Skipping {file}\")\n",
    "            continue\n",
    "            \n",
    "        os.rename(file, new_name)\n",
    "        print(f\"Renamed: {file} -> {new_name}\")\n",
    "        \n",
    "        # Close the CDF file\n",
    "        cdf.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"Renaming complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79cbb5-a1c3-4801-8eef-d4258752d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converted downloaded .cdf files to .csv format\n",
    "\n",
    "directory = \"Directory/containing/downloaded/bulk/cdf/files/from/SWIS/website\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    cdf_file = os.path.join(directory, filename) \n",
    "    cdf_file = pycdf.CDF(cdf_file)\n",
    "\n",
    "    data_dict = {}\n",
    "    for var in cdf_file:\n",
    "        try:\n",
    "            # Flatten the variable if it's multidimensional\n",
    "            data = cdf_file[var][:]\n",
    "            if hasattr(data[0], '__len__'):\n",
    "                print(f\"Skipping multidimensional variable: {var}\")\n",
    "                continue\n",
    "            data_dict[var] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {var}: {e}\")\n",
    "\n",
    "    # Convert to pandas DataFrame\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    # Save as CSV\n",
    "    df.to_csv(f'/Users/vishrutgupta/Desktop/ISRO_bah_2025/SWIS_renamed/csv_full/{filename}.csv', index=False)\n",
    "\n",
    "print(\"Conversion complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bdcf1-076c-4cb1-8922-c554f1cf52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged CACTus data with SWIS files\n",
    "\n",
    "def check_for_file(date):\n",
    "    directory = \"/Users/vishrutgupta/Desktop/ISRO_bah_2025/merged_data\"\n",
    "    # os.rmdir(directory)\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if (date[0] == filename[:4]) and (date[1] == filename[5:7]) and (date[2] == filename[8:10]):\n",
    "            df = pd.read_csv(filepath)\n",
    "            os.remove(filepath)\n",
    "            return filename, df\n",
    "\n",
    "    directory = \"/Users/vishrutgupta/Desktop/ISRO_bah_2025/SWIS_renamed/csv_full\"\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if (date[0] == filename[:4]) and (date[1] == filename[5:7]) and (date[2] == filename[8:10]):\n",
    "            df = pd.read_csv(filepath)\n",
    "            return filename, df        \n",
    "    return None, None\n",
    "\n",
    "\n",
    "# Extract CACTus data from the net from May 2024 till July 2025\n",
    "cact_data = pd.read_csv('CACTus_data/all_cme_data.csv')\n",
    "\n",
    "# Loop through row-wise data from cactus file and merge with SWIS data\n",
    "for index, row in cact_data.iterrows():\n",
    "    t0 = row.iloc[1]\n",
    "    t0 = t0.split()\n",
    "    date = t0[0].split('/')\n",
    "    t0 = t0[1].split(':')\n",
    "    filename, swis_data = check_for_file(date)\n",
    "\n",
    "    if swis_data is not None:\n",
    "        if 'CME' not in swis_data.columns:\n",
    "            swis_data['CME'] = 0\n",
    "        if 'HALO' not in swis_data.columns:\n",
    "            swis_data['HALO'] = 0\n",
    "        # Get SWIS data and assign cme/halo columns\n",
    "        start_time = datetime(int(date[0]), int(date[1]), int(date[2]), int(t0[0]), int(t0[1]))\n",
    "        hr = int(t0[0]) + int(row.iloc[3])\n",
    "        if hr > 23:\n",
    "            hr = hr - 24\n",
    "        end_time = datetime(int(date[0]), int(date[1]), int(date[2]), hr, int(t0[1]))\n",
    "        for sno, obs in swis_data.iterrows():\n",
    "            date_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "            swis_time = datetime.strptime(obs.iloc[0], date_format)\n",
    "            if swis_time > start_time and swis_time < end_time:\n",
    "                swis_data.at[sno, 'CME'] = 1\n",
    "                if row.iloc[-1] == \"II\":\n",
    "                    swis_data.at[sno, 'HALO'] = 2\n",
    "                elif row.iloc[-1] == \"III\":\n",
    "                    swis_data.at[sno, 'HALO'] = 3\n",
    "                elif row.iloc[-1] == \"IV\":\n",
    "                    swis_data.at[sno, 'HALO'] = 4\n",
    "                else:\n",
    "                    swis_data.at[sno, 'HALO'] = 1\n",
    "\n",
    "        # Save processed version\n",
    "        output_file = os.path.join('/Users/vishrutgupta/Desktop/ISRO_bah_2025/merged_data', filename.replace('.cdf.csv', '.csv'))\n",
    "        swis_data.to_csv(output_file, index=False)\n",
    "        print(f\"row {index} computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e31693-5606-4ddc-8c94-380fead7c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine multiple .csv files into one\n",
    "\n",
    "file_paths = glob.glob(\"/Users/vishrutgupta/Desktop/ISRO_bah_2025/merged_data/*.csv\")\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each file and append data\n",
    "for idx, file_path in enumerate(file_paths):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if idx == 0:                    # skip header\n",
    "        merged_data = df\n",
    "    else:\n",
    "        merged_data = pd.concat([merged_data, df], ignore_index=True)\n",
    "\n",
    "merged_data = merged_data.sort_values(by=['epoch_for_cdf_mod'], ignore_index=True)\n",
    "merged_data.to_csv(\"/Users/vishrutgupta/Desktop/ISRO_bah_2025/merged_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
